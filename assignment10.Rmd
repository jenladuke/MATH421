
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Use the `Adult Census Income` dataset.  We will predict the income (whether or not it is more than 50k or not) of an adult. Import the dataset.  Partition the data into 80% training and 20% testing.  
```{r}
library(tidyverse)
df = read.csv('adult_census_missing.csv')

df = df %>% 
  rename(target=income) 

df = df %>%
  mutate(target = as.factor(target),
         education = as.factor(education),
         workclass = as.factor(workclass),
         marital.status = as.factor(marital.status),
         occupation = as.factor(occupation),
         relationship = as.factor(relationship),
         race = as.factor(race),
         sex = as.factor(sex),
         native.country = as.factor(native.country))

df = drop_na(df)
  
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
```


2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 
```{r}
library(rpart) 
tree_model = rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))
```

  - Calculate the accuracy of the model on the testing data. Notice that the positive outcome here is not `1` but `>50K` or `<50K`. 
```{r}
pred = predict(tree_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]
```

  
  - Plot the tree
```{r}
library(rattle)
fancyRpartPlot(tree_model)
```
  
  
  - Plot the variable importance by the tree
```{r}
tree_model$variable.importance
```

  
3. Create 3 more trees and compare the testing accuracy of these trees, which tree give the highest testing accuracy.
```{r}
library(rpart) 
tree_model = rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 5))
pred = predict(tree_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]

library(rpart) 
tree_model = rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 2))
pred = predict(tree_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]

library(rpart) 
tree_model = rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 1))
pred = predict(tree_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]
```
## Changing the maxdepth to a higher number,5, creates a more accurate decision tree. 

4. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees.   
  - Calculate the accuracy of the model on the testing data. 
```{r}
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]
```

  
  - Plot the variable importance by the forest
```{r}
importance(forest_model)
```
  

5. Create 3 more forests and compare the testing accuracy of these forests, which forest give the highest testing accuracy.
```{r}
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 900)
pred <- predict(forest_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]

library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 800)
pred <- predict(forest_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]

library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 200)
pred <- predict(forest_model, df_test, type = "class")
cm = confusionMatrix(data = pred, reference = df_test$target, positive = "<=50K")
cm$overall[1]
```
## Decreasing the number of trees will decrease the accuracy. The forest with 1000 trees is most accurate. 

6. What is the best model (in term of testing accuracy) among all models (including trees and forests) you have trained?

Best model is the forest with 1000 trees since the accuracy is 86.99%, highest among the training models. 


